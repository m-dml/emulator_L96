{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('/gpfs/home/nonnenma/projects/emulators/simulators/L96'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from L96_base import f1, f2, J1, J1_init, f1_juliadef, f2_juliadef\n",
    "\n",
    "def predictor_corrector(fun, y0, times, alpha=0.5):\n",
    "\n",
    "    y = np.zeros((len(times), *y0.shape))\n",
    "    y[0] = y0\n",
    "    for i in range(1,len(times)):        \n",
    "        dt = times[i] - times[i-1]\n",
    "\n",
    "        f0 = fun(times[i-1], y[i-1])\n",
    "        f1 = fun(times[i],   y[i-1] + dt*f0)\n",
    "\n",
    "        y[i] = y[i-1] + dt * (alpha*f0 + (1-alpha)*f1)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, h, b, c = 10, 1, 10, 10\n",
    "K = 36\n",
    "T, dt = 5, 0.001\n",
    "\n",
    "X_init = F * (0.5 + np.random.randn(K) * 1.0)\n",
    "dX_dt = np.empty(X_init.size, dtype=X_init.dtype)\n",
    "\n",
    "def fun(t, x):\n",
    "    return f1(x, F, dX_dt, K)\n",
    "\n",
    "times = np.linspace(0, T, np.floor(T/dt)+1)\n",
    "out = predictor_corrector(fun=fun, y0=X_init.copy(), times=times, alpha=0.5)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(out.T, aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn local emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('/gpfs/home/nonnenma/projects/seasonal_forecasting/code/weatherbench'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.pytorch.layers import setup_conv, ResNetBlock, PeriodicConv2D\n",
    "from src.pytorch.util import init_torch_device\n",
    "\n",
    "device = init_torch_device()\n",
    "dtype = torch.float32\n",
    "dtype_np = np.float32\n",
    "\n",
    "class Dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, data, offset=1, \n",
    "                 start=None, end=None, \n",
    "                 normalize=False, randomize_order=True):\n",
    "\n",
    "        self.data = data.copy()\n",
    "\n",
    "        self.offset = offset\n",
    "        if start is None or end is None:\n",
    "            start, end = 0,  self.data.shape[0]-self.offset\n",
    "        assert end > start\n",
    "        self.start, self.end = start, end\n",
    "\n",
    "        self.normalize = normalize\n",
    "        self.mean, self.std = 0., 1.\n",
    "        if self.normalize:\n",
    "            self.mean = self.data.mean(axis=0).reshape(1,-1)\n",
    "            self.std = self.data.std(axis=0).reshape(1,-1)\n",
    "            self.data = (self.data - self.mean) / self.std \n",
    "\n",
    "        self.randomize_order = randomize_order\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Generate one batch of data \"\"\"\n",
    "        return np.atleast_2d(self.data[np.asarray(index),:])\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Return iterable over data in random order \"\"\"\n",
    "        iter_start, iter_end = self.divide_workers()\n",
    "        if self.randomize_order:\n",
    "            idx = torch.randperm(iter_end - iter_start, device='cpu') + iter_start\n",
    "        else: \n",
    "            idx = torch.arange(iter_start, iter_end, requires_grad=False, device='cpu')\n",
    "\n",
    "        X = self.data[idx,:].reshape(len(idx), 1, -1)\n",
    "        y = self.data[idx+self.offset,:].reshape(len(idx), 1, -1)\n",
    "\n",
    "        return zip(X, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def divide_workers(self):\n",
    "        \"\"\" parallelized data loading via torch.util.data.Dataloader \"\"\"\n",
    "        if torch.utils.data.get_worker_info() is None:\n",
    "            iter_start = torch.tensor(self.start, requires_grad=False, dtype=torch.int, device='cpu')\n",
    "            iter_end = torch.tensor(self.end, requires_grad=False, dtype=torch.int, device='cpu')\n",
    "        else: \n",
    "            raise NotImplementedError('had no need for parallelization yet')\n",
    "\n",
    "        return iter_start, iter_end\n",
    "\n",
    "out32 = out.astype(dtype=dtype_np)\n",
    "    \n",
    "dg_train = Dataset(data=out32, offset=1, normalize=True, start=0, end=np.floor(out.shape[0]*0.8))\n",
    "dg_val   = Dataset(data=out32, offset=1, normalize=True, \n",
    "                   start=np.ceil(out.shape[0]*0.8), end=np.floor(out.shape[0]*0.9))\n",
    "batch_size = 32\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dg_val, batch_size=batch_size, drop_last=False, num_workers=0 \n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dg_train, batch_size=batch_size, drop_last=True, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyNetwork(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_filters, n_channels_in = 1, n_channels_out = 1):\n",
    "\n",
    "        super(TinyNetwork, self).__init__()\n",
    "        n_in = n_channels_in\n",
    "        self.layers3x3 = []\n",
    "        for i in range(len(n_filters)):\n",
    "            n_out = n_filters[i]\n",
    "            layer = torch.nn.Conv1d(in_channels = n_in, \n",
    "                                    out_channels = n_out, \n",
    "                                    kernel_size = 3, \n",
    "                                    padding = (3-1)//2, \n",
    "                                    bias = True, \n",
    "                                    padding_mode = 'zeros')\n",
    "            self.layers3x3.append(layer)\n",
    "            n_in = n_out\n",
    "        self.layers3x3 = torch.nn.ModuleList(self.layers3x3)\n",
    "\n",
    "        self.final = torch.nn.Conv1d(in_channels=n_in,\n",
    "                                     out_channels=n_channels_out,\n",
    "                                     kernel_size= 1)\n",
    "        self.nonlinearity = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers3x3:\n",
    "            x = self.nonlinearity(layer(x))\n",
    "        return self.final(x)\n",
    "\n",
    "model = TinyNetwork(n_filters = [32, 32])\n",
    "\n",
    "model.forward(torch.as_tensor(np.random.normal(size=(10, 1, 36)), device='cpu', dtype=dtype)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.pytorch.train import train_model\n",
    "\n",
    "loss_fun = torch.nn.functional.mse_loss\n",
    "\n",
    "train_out = train_model(model, train_loader, validation_loader, device, model_forward=model.forward, loss_fun=loss_fun, \n",
    "            lr=0.001, lr_min=1e-5, lr_decay=0.2, weight_decay=0.,\n",
    "            max_epochs=200, max_patience=10, max_lr_patience=10, eval_every=None,\n",
    "            verbose=True, save_dir=None)\n",
    "\n",
    "training_loss = train_out['training_loss'][-1]\n",
    "validation_loss = train_out['validation_loss']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_simulate(y0, T):\n",
    "    x = np.empty((T+1, *y0.shape))\n",
    "    x[0] = y0.copy()\n",
    "    xx = torch.as_tensor(x[0], device='cpu', dtype=dtype).reshape(1,1,-1)\n",
    "    for i in range(1,T+1):\n",
    "        xx = model.forward(xx)\n",
    "        x[i] = xx.detach().numpy().copy()\n",
    "    return x\n",
    "\n",
    "out_model = model_simulate(y0=X_init.copy(), T=len(times))\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(out32.T, aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(out_model.T, aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('model-reconstructed simulation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,9))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(out32[:100].T - X_init.reshape(-1,1), aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation, differences to yo')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(out_model[:100].T - X_init.reshape(-1,1), aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('model-reconstructed simulation, differences to yo')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,12))\n",
    "for i in range(3):\n",
    "    \n",
    "    t0 = int(np.floor((i+1)*(len(times)-1)*0.25))\n",
    "    T_ = 200\n",
    "    y0 = out32[t0]\n",
    "\n",
    "    out_model = model_simulate(y0=y0.copy(), T=T_)\n",
    "\n",
    "    cmax = np.maximum((out32[t0:t0+T_].T - y0.reshape(-1,1)).max(),\n",
    "                      (out_model.T - y0.reshape(-1,1)).max())\n",
    "    cmin = np.minimum((out32[t0:t0+T_].T - y0.reshape(-1,1)).min(),\n",
    "                      (out_model.T - y0.reshape(-1,1)).min())\n",
    "    \n",
    "    plt.subplot(3,2,2*i+1)\n",
    "    plt.imshow(out32[t0:t0+T_].T - y0.reshape(-1,1), aspect='auto', vmax=cmax, vmin=cmin)\n",
    "    \n",
    "    \n",
    "    if i == 2:\n",
    "        plt.xlabel('time')\n",
    "    plt.ylabel(f\"T' = {(i+1)*25/100}*T\")\n",
    "    plt.title('numerical simulation')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(3,2,2*i+2)\n",
    "    plt.imshow(out_model.T - y0.reshape(-1,1), aspect='auto', vmax=cmax, vmin=cmin)\n",
    "    if i == 2:\n",
    "        plt.xlabel('time')\n",
    "    plt.ylabel('location')\n",
    "    plt.colorbar()\n",
    "    plt.title('model-reconstructed simulation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
