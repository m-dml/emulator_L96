{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import L96sim\n",
    "\n",
    "res_dir = '/gpfs/work/nonnenma/results/emulators/L96/'\n",
    "data_dir = '/gpfs/work/nonnenma/data/emulators/L96/'\n",
    "dtype = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load specific experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from L96_emulator.run import setup\n",
    "\n",
    "conf_exp = '05_resnet_1x1convs_predictState' #'template'\n",
    "args = setup(conf_exp=f'experiments/{conf_exp}.yml')\n",
    "args.pop('conf_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load / simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from L96sim.L96_base import f1, f2, J1, J1_init, f1_juliadef, f2_juliadef\n",
    "from L96_emulator.util import predictor_corrector\n",
    "\n",
    "try: \n",
    "    K, J, T, dt = args['K'], args['J'], args['T'], args['dt']\n",
    "    spin_up_time = args['spin_up_time']\n",
    "except:\n",
    "    F, h, b, c = 10, 1, 10, 10\n",
    "    K, J, T, dt = 36, 10, 605, 0.001\n",
    "    spin_up_time = 5.\n",
    "\n",
    "fn_data = f'out_K{K}_J{J}_T{T}_dt0_{str(dt)[2:]}'\n",
    "\n",
    "resimulate = False\n",
    "if resimulate:\n",
    "    print('simulating data')\n",
    "    X_init = F * (0.5 + np.random.randn(K*(J+1)) * 1.0) / np.maximum(J,10)\n",
    "    dX_dt = np.empty(X_init.size, dtype=X_init.dtype)\n",
    "    times = np.linspace(0, T, np.floor(T/dt)+1)\n",
    "\n",
    "    if J > 0:\n",
    "        def fun(t, x):\n",
    "            return f2(x, F, h, b, c, dX_dt, K, J)\n",
    "    else:\n",
    "        def fun(t, x):\n",
    "            return f1(x, F, dX_dt, K)\n",
    "\n",
    "    out = predictor_corrector(fun=fun, y0=X_init.copy(), times=times, alpha=0.5)\n",
    "\n",
    "    # filename for data storage\n",
    "    #np.save(data_dir + fn_data, out.astype(dtype=dtype))\n",
    "else:\n",
    "    print('loading data')\n",
    "    out = np.load(data_dir + fn_data + '.npy')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(out.T, aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optional: create short comparison solution with different step size for numerical solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from L96_emulator.eval import solve_from_init\n",
    "\n",
    "solver_comparison = True \n",
    "\n",
    "if solver_comparison:\n",
    "    try: \n",
    "        print(F, h, b, c)\n",
    "    except: \n",
    "        F, h, b, c = 10, 1, 10, 10\n",
    "\n",
    "    T_burnin, T_comparison = int(spin_up_time/dt), 5000\n",
    "    out2 = solve_from_init(K, J, \n",
    "                           T_burnin=T_burnin, T_=T_comparison, dt=dt, \n",
    "                           F=F, h=h, b=b, c=c, \n",
    "                           data=out, dilation=2, norm_mean=0., norm_std=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn local emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%run -i 'main_train.py -c experiments/template.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from L96_emulator.eval import load_model_from_exp_conf\n",
    "\n",
    "model, model_forward, training_outputs = load_model_from_exp_conf(res_dir, args)\n",
    "\n",
    "if not training_outputs is None:\n",
    "    training_loss, validation_loss = training_outputs['training_loss'], training_outputs['validation_loss']\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    seq_length = args['seq_length']\n",
    "    plt.semilogy(validation_loss, label=conf_exp+ f' ({seq_length * (J+1)}-dim)')\n",
    "    plt.title('training')\n",
    "    plt.ylabel('validation error')\n",
    "    plt.legend()\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.show()\n",
    "\n",
    "model.layers_ks1, model.layers3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from L96_emulator.run import sel_dataset_class\n",
    "from L96_emulator.util import sortL96fromChannels, sortL96intoChannels\n",
    "from L96_emulator.eval import get_rollout_fun, plot_rollout\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "DatasetClass = sel_dataset_class(prediction_task=args['prediction_task'])\n",
    "dg_train = DatasetClass(data=out, J=J, offset=args['lead_time'], normalize=True, \n",
    "                   start=int(args['spin_up_time']/args['dt']), \n",
    "                   end=int(np.floor(out.shape[0]*args['train_frac'])))\n",
    "\n",
    "model_simulate = get_rollout_fun(dg_train, model_forward, args['prediction_task'])\n",
    "\n",
    "T_start, T_dur = int(spin_up_time/dt), 400\n",
    "out_model = model_simulate(y0=dg_train[T_start].copy(), \n",
    "                           dy0=dg_train[T_start]-dg_train[T_start-dg_train.offset],\n",
    "                           T=T_dur)\n",
    "out_model = sortL96fromChannels(out_model * dg_train.std + dg_train.mean)\n",
    "\n",
    "\n",
    "fig = plot_rollout(out, out_model, out_comparison=out2, T_start=T_start, T_dur=T_dur, K=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adams_bashfort(model_simulate, dg_train, T_start, T_dur):\n",
    "\n",
    "    y = dg_train[T_start].copy()\n",
    "    dy_prev = model_simulate(y0=y, dy0=None, T=1)[-1] - y    \n",
    "\n",
    "    out = np.empty((T_dur+1, *y.shape[1:]))\n",
    "    out[0] = y.copy()\n",
    "    y += dy_prev\n",
    "    out[1] = y.copy()\n",
    "\n",
    "    for t in range(2,T_dur+1):\n",
    "        dy_new = model_simulate(y0=y, dy0=None, T=1)[-1] - y\n",
    "        y += 0.5 * (3 * dy_new - 1. * dy_prev)\n",
    "        dy_prev = dy_new\n",
    "        out[t] = y\n",
    "\n",
    "    return out\n",
    "\n",
    "out_ab = adams_bashfort(model_simulate, dg_train, T_start, T_dur=T_dur)\n",
    "out_ab = sortL96fromChannels(out_ab * dg_train.std + dg_train.mean)\n",
    "\n",
    "fig = plot_rollout(out, out_model, out_comparison=out_ab, T_start=T_start, T_dur=T_dur)\n",
    "plt.subplot(1,2,2)\n",
    "plt.legend(['direct model reconstruction', 'Adams-Bashfort explicit step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug corner - might not execture anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### older fits - comparison of validation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "conf_exps = [\n",
    "            f'0{i}_resnet_1x1convs_predictState' for i in range(1,6) # initially just gave the network fits version numbers V0 - V9\n",
    "          ]\n",
    "\n",
    "def find_weights(fn):\n",
    "    return fn[-3:] == '.pt'\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for i, conf_exp in enumerate(conf_exps):\n",
    "    args = setup(conf_exp=f'experiments/{conf_exp}.yml')\n",
    "    args.pop('conf_exp')\n",
    "    exp_id, dim = args['exp_id'], args['J']+1\n",
    "\n",
    "    save_dir = res_dir + 'models/' + exp_id + '/'\n",
    "\n",
    "\n",
    "    #plt.subplot(1,2,1)\n",
    "    try:\n",
    "        training_outputs = np.load(save_dir + '_training_outputs' + '.npy', allow_pickle=True)[()]\n",
    "        training_loss, validation_loss = training_outputs['training_loss'], training_outputs['validation_loss']\n",
    "        plt.semilogy(validation_loss, label=exp_id + f' ({dim}D)')\n",
    "    except:\n",
    "        plt.semilogy(1., label=exp_id + f' ({dim}D)')            \n",
    "    plt.title('training')\n",
    "\n",
    "plt.ylabel('validation error')\n",
    "plt.legend()\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "plt.figure(figsize=(16,4))\n",
    "cellText = np.hstack((np.array(conf_exps).reshape(-1,1), np.around(RMSEall,2)))\n",
    "collabel=('experiment', f'RMSE {lead_time}h, z 500', f'RMSE {lead_time}h, t 850')\n",
    "plt.axis('tight')\n",
    "plt.axis('off')\n",
    "plt.table(cellText=cellText,colLabels=collabel,loc='center')\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T_burnin = 10000\n",
    "out_model = model_simulate(y0=dg_train[T_burnin].copy(), dy0 = None, T=T_)#.reshape(-1, K*(J+1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(J+1):\n",
    "    plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(2,) ))[:,i], \n",
    "             'b--')\n",
    "plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(2,) ))[:,0], 'k', linewidth=2,\n",
    "         label='slow variables')\n",
    "plt.semilogy(-1, 1, 'b--', label=f'fast variables (J={str(J)})')\n",
    "plt.axis([0,20,0.0000001, 0.5])\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('error over iterations, per variable type')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for i in range(J+1):\n",
    "    plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(2,) ))[:,i], \n",
    "             'b--')\n",
    "plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(2,) ))[:,0], 'k', linewidth=2,\n",
    "         label='slow variables')\n",
    "plt.semilogy(-1, 1, 'b--', label=f'fast variables (J={str(J)})')\n",
    "plt.axis([0,1300,0.0000001, 1000])\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('error over iterations, per variable type')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T_burnin = 10000\n",
    "out_model = model_simulate(y0=dg_train[T_burnin].copy(), T=T_)#.reshape(-1, K*(J+1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(K):\n",
    "    plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(1,) ))[:,i], \n",
    "             'b--')\n",
    "plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(1,) ))[:,0], 'k', linewidth=2,\n",
    "         label='slow variables')\n",
    "plt.semilogy(-1, 1, 'b--', label=f'fast variables (J={str(J)})')\n",
    "plt.axis([0,20,0.0000001, 0.5])\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('error over iterations, per variable type')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for i in range(K):\n",
    "    plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(1,) ))[:,i], \n",
    "             'b--')\n",
    "plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(1,) ))[:,0], 'k', linewidth=2,\n",
    "         label='slow variables')\n",
    "plt.semilogy(-1, 1, 'b--', label=f'fast variables (J={str(J)})')\n",
    "plt.axis([0,1300,0.0000001, 1000])\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('error over iterations, per variable type')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 10000\n",
    "plt.plot((dg_train.mean_in + dg_train.std_in * dg_train[t][0,:,:]).reshape(K*(J+1)) - out[t])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 5000\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(dg_train[t+0].flatten(), label='t=0')\n",
    "plt.plot(dg_train[t+1].flatten(), label='t=1')\n",
    "plt.plot(model_simulate(y0=dg_train[t+0].copy(), T=1)[-1,:,:].flatten(), 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 10000\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(dg_train[t+1].flatten() - dg_train[t+0].flatten(), label='sim')\n",
    "plt.plot(model_simulate(y0=dg_train[t+0].copy(), T=1)[-1,:,:].flatten()  - dg_train[t+0].flatten(), label='model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in [0, 100, 1000, 10000]:\n",
    "    plt.plot(model_simulate(y0=dg_train[t+0].copy(), T=1)[-1,:,:].flatten()  - dg_train[t+1].flatten(), label='model')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.semilogy(np.std(np.diff(dg_train[np.arange(T_+1)+ T_burnin].reshape(-1,(J+1)*K), axis=0), axis=0))\n",
    "plt.xlabel('variable ID (slow: first K=36)')\n",
    "plt.ylabel('std')\n",
    "plt.title('variability of 1-step temporal differences')\n",
    "plt.axis([0, 397, 0.001, 0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vmin, vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "T_burnin = 10000\n",
    "T_ = 10000\n",
    "plt.imshow(dg_train[np.arange(T_+1)+ T_burnin].reshape(-1,(J+1)*K).T, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dg_train[np.arange(T_+1)+ T_burnin][:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "T_burnin = 10000\n",
    "T_ = 10000\n",
    "plt.imshow(dg_train[np.arange(T_+1)+ T_burnin][:,:,0].reshape(-1,J+1).T, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,9))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(dg_train[np.arange(100)+T_burnin].reshape(100,-1).T - dg_train[T_burnin].reshape(-1,1), aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation, differences to yo')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(out_model[:100].reshape(100,-1).T - dg_train[T_burnin].reshape(-1,1), aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('model-reconstructed simulation, differences to yo')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from L96_emulator.dataset import DatasetRelPred\n",
    "dg_train = DatasetRelPred(data=out, J=J, offset=temporal_offset, normalize=True, \n",
    "                          start=T_burnin, \n",
    "                          end=int(np.floor(out.shape[0]*0.8)))\n",
    "dg_val   = DatasetRelPred(data=out, J=J, offset=temporal_offset, normalize=True, \n",
    "                          start=int(np.ceil(out.shape[0]*0.8)), \n",
    "                          end=int(np.floor(out.shape[0]*0.9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ct = 0\n",
    "s = np.zeros((474000, 11, 36))\n",
    "for batch in dg_train:\n",
    "    X,Y = batch\n",
    "    #print(X.shape, Y.shape)\n",
    "    \n",
    "    s[ct] = Y.copy()\n",
    "    ct += 1\n",
    "    if ct > 1000:\n",
    "        pass #break\n",
    "m = np.mean(s, axis=(0,2))\n",
    "s = np.std(s, axis=(0,2))\n",
    "print(m, s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
