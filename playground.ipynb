{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('/gpfs/home/nonnenma/projects/emulators/simulators/L96'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "res_dir = '/gpfs/work/nonnenma/results/emulators/L96/'\n",
    "data_dir = '/gpfs/work/nonnenma/data/emulators/L96/'\n",
    "dtype = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load specific experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.run import setup\n",
    "\n",
    "conf_exp = 'template'\n",
    "args = setup(conf_exp=f'experiments/{conf_exp}.yml')\n",
    "args.pop('conf_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load / simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from L96_base import f1, f2, J1, J1_init, f1_juliadef, f2_juliadef\n",
    "from L96_emulator.util import predictor_corrector\n",
    "\n",
    "try: \n",
    "    K, J, T, dt = args['K'], args['J'], args['T'], args['dt']\n",
    "    spin_up_time = args['spin_up_time']\n",
    "except:\n",
    "    F, h, b, c = 10, 1, 10, 10\n",
    "    K, J, T, dt = 36, 3, 605, 0.001\n",
    "    spin_up_time = 5.\n",
    "\n",
    "fn_data = f'out_K{K}_J{J}_T{T}_dt0_{str(dt)[2:]}'\n",
    "\n",
    "resimulate = False\n",
    "if resimulate:\n",
    "    print('simulating data')\n",
    "    X_init = F * (0.5 + np.random.randn(K*(J+1)) * 1.0) / np.maximum(J,10)\n",
    "    dX_dt = np.empty(X_init.size, dtype=X_init.dtype)\n",
    "    times = np.linspace(0, T, np.floor(T/dt)+1)\n",
    "\n",
    "    if J > 0:\n",
    "        def fun(t, x):\n",
    "            return f2(x, F, h, b, c, dX_dt, K, J)\n",
    "    else:\n",
    "        def fun(t, x):\n",
    "            return f1(x, F, dX_dt, K)\n",
    "\n",
    "    out = predictor_corrector(fun=fun, y0=X_init.copy(), times=times, alpha=0.5)\n",
    "\n",
    "    # filename for data storage\n",
    "    np.save(data_dir + fn_data, out.astype(dtype=dtype))\n",
    "else:\n",
    "    print('loading data')\n",
    "    out = np.load(data_dir + fn_data + '.npy')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(out.T, aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optional: create short comparison solution with different step size for numerical solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solver_comparison = True \n",
    "if solver_comparison:\n",
    "    try: \n",
    "        print(F, h, b, c)\n",
    "    except: \n",
    "        F, h, b, c = 10, 1, 10, 10\n",
    "\n",
    "    T_ = 5000\n",
    "    T_burnin = int(spin_up_time/dt) # rough time [s] for model state to have 'forgotten' its initial state\n",
    "\n",
    "    dX_dt = np.empty(K*(J+1), dtype=np.float32)\n",
    "    times = np.arange(0, (T_+1)*dt, 0.5*dt)\n",
    "\n",
    "    if J > 0:\n",
    "        def fun(t, x):\n",
    "            return f2(x, F, h, b, c, dX_dt, K, J)\n",
    "    else:\n",
    "        def fun(t, x):\n",
    "            return f1(x, F, dX_dt, K)\n",
    "\n",
    "    out2 = predictor_corrector(fun=fun, y0=out[T_burnin], times=times, alpha=0.5)[::2,:]\n",
    "    out2 = out2.reshape(-1,(J+1)*K)\n",
    "\n",
    "    from L96_emulator.dataset import Dataset\n",
    "\n",
    "    temporal_offset = 1\n",
    "    dg_train = Dataset(data=out, J=J, offset=temporal_offset, normalize=True, \n",
    "                       start=T_burnin, \n",
    "                       end=int(np.floor(out.shape[0]*0.8)))\n",
    "    out2 = (out2.reshape(-1,J+1,K) - dg_train.mean) / dg_train.std\n",
    "    out2 = out2.reshape(-1,(J+1)*K)\n",
    "    plt.plot(np.sqrt(np.mean( (out2 - dg_train[np.arange(T_+1)+ T_burnin].reshape(-1,(J+1)*K))**2, axis=1 )), 'k--',\n",
    "            label='solver 2x temp. resol. vs sim')\n",
    "    plt.axis([0, 2000, 0, 1.6])\n",
    "    plt.title('missmatch over time')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('RMSE (on z-scored data)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn local emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%run -i 'main_train.py -c experiments/template.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from L96_emulator.networks import named_network\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('/gpfs/home/nonnenma/projects/seasonal_forecasting/code/weatherbench'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.pytorch.util import init_torch_device\n",
    "\n",
    "dtype = torch.float32\n",
    "device = init_torch_device()\n",
    "\n",
    "net_kwargs = {\n",
    "        'filters': args['filters'],\n",
    "        'kernel_sizes': args['kernel_sizes'],\n",
    "        'filters_ks1_init': args['filters_ks1_init'],\n",
    "        'filters_ks1_inter': args['filters_ks1_inter'],\n",
    "        'filters_ks1_final': args['filters_ks1_final']\n",
    "}\n",
    "\n",
    "model, model_forward = named_network(model_name=args['model_name'], \n",
    "                                     n_input_channels=args['J']+1, \n",
    "                                     n_output_channels=args['J']+1,\n",
    "                                     seq_length=args['seq_length'],\n",
    "                                     **net_kwargs)\n",
    "    \n",
    "test_input = np.random.normal(size=(10, args['seq_length']*(args['J']+1), args['K']))\n",
    "print(f'model output shape to test input of shape {test_input.shape}', \n",
    "      model.forward(torch.as_tensor(test_input, device=device, dtype=dtype)).shape)\n",
    "\n",
    "print('total #parameters: ', np.sum([np.prod(item.shape) for item in model.state_dict().values()]))\n",
    "\n",
    "lead_time, exp_id = args['lead_time'], args['exp_id']\n",
    "save_dir = res_dir + 'models/' + exp_id + '/'\n",
    "model_fn = f'{exp_id}_dt{lead_time}.pt'\n",
    "model.load_state_dict(torch.load(save_dir + model_fn, map_location=torch.device(device)))\n",
    "\n",
    "model.layers_ks1, model.layers3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from L96_emulator.dataset import Dataset, DatasetRelPred, DatasetRelPredPast\n",
    "from L96_emulator.run import sel_dataset_class\n",
    "\n",
    "DatasetClass = sel_dataset_class(prediction_task=args['prediction_task'])\n",
    "train_frac, validation_frac = args['train_frac'], args['validation_frac']\n",
    "\n",
    "dg_train = DatasetClass(data=out, J=J, offset=temporal_offset, normalize=True, \n",
    "                   start=T_burnin, \n",
    "                   end=int(np.floor(out.shape[0]*train_frac)))\n",
    "dg_val   = DatasetClass(data=out, J=J, offset=temporal_offset, normalize=True, \n",
    "                   start=int(np.ceil(out.shape[0]*train_frac)), \n",
    "                   end=int(np.floor(out.shape[0]*(train_frac+validation_frac))))\n",
    "\n",
    "if isinstance(dg_train, DatasetRelPredPast):\n",
    "\n",
    "    std_out = torch.as_tensor(dg_train.std_out, device='cpu', dtype=dtype)\n",
    "    mean_out = torch.as_tensor(dg_train.mean_out, device='cpu', dtype=dtype)\n",
    "\n",
    "    def model_simulate(y0, dy0, T):\n",
    "        x = np.empty((T+1, *y0.shape[1:]))\n",
    "        x[0] = y0.copy()\n",
    "        xx = torch.as_tensor(x[0], device='cpu', dtype=dtype)\n",
    "        dx = torch.as_tensor(dy0.copy(), device='cpu', dtype=dtype)\n",
    "        for i in range(1,T+1):\n",
    "            xxo = xx * 1.\n",
    "            #print(xx.shape, dx.shape)\n",
    "            xx = std_out * model.forward(torch.cat((xx.reshape(1,J+1,K), dx), axis=1)) + mean_out + xx.reshape(1,J+1,-1)\n",
    "            dx = xx - xxo\n",
    "            x[i] = xx.detach().numpy().copy()\n",
    "        return x\n",
    "    \n",
    "elif isinstance(dg_train, Dataset): \n",
    "\n",
    "    def model_simulate(y0, dy0, T):\n",
    "        x = np.empty((T+1, *y0.shape[1:]))\n",
    "        x[0] = y0.copy()\n",
    "        xx = torch.as_tensor(x[0], device='cpu', dtype=dtype).reshape(1,1,-1)\n",
    "        for i in range(1,T+1):\n",
    "            xx = model.forward(xx.reshape(1,J+1,-1))\n",
    "            x[i] = xx.detach().numpy().copy()\n",
    "        return x\n",
    "\n",
    "T_burnin = int(spin_up_time/dt)\n",
    "T_ = 500 #(out.shape[0]-1)//10000    \n",
    "out_model = model_simulate(y0=dg_train[T_burnin].copy(), \n",
    "                           dy0=dg_train[T_burnin]-dg_train[T_burnin-dg_train.offset],\n",
    "                           T=T_)#.reshape(-1, K*(J+1))\n",
    "\n",
    "vmax = np.maximum(np.nanmax(dg_train[np.arange(T_burnin,T_burnin+T_)]),\n",
    "                  np.nanmax(out_model))\n",
    "vmin = np.minimum(np.nanmin(dg_train[np.arange(T_burnin,T_burnin+T_)]),\n",
    "                  np.nanmin(out_model.T))\n",
    "\n",
    "vmax, vmin = 5, -5\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(dg_train[np.arange(T_+1)+ T_burnin].reshape(-1,(J+1)*K).T, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(out_model.reshape(-1,(J+1)*K).T, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('model-reconstructed simulation')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.sqrt(np.mean( (out_model - dg_train[np.arange(T_+1)+ T_burnin])**2, axis=(1,2) )), \n",
    "         label='model-reconstruction vs sim')\n",
    "\n",
    "try:\n",
    "    plt.plot(np.sqrt(np.mean( (out2[:T_+1] - dg_train[np.arange(T_+1)+ T_burnin].reshape(-1,(J+1)*K))**2, axis=1 )), 'k--',\n",
    "            label='solver 2x temp. resol. vs sim')\n",
    "except:\n",
    "    pass\n",
    "#plt.axis([0, np.minimum(500, T_), 0, 1.6])\n",
    "plt.title('missmatch over time')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('RMSE (on z-scored data)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "try: \n",
    "    training_outputs = np.load(save_dir + '_training_outputs' + '.npy', allow_pickle=True)[()]\n",
    "    training_loss, validation_loss = training_outputs['training_loss'], training_outputs['validation_loss']\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.semilogy(validation_loss, label=conf_exp+ f' ({seq_length * (J+1)}-dim)')\n",
    "    plt.title('training')\n",
    "    plt.ylabel('validation error')\n",
    "    plt.legend()\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.show()    \n",
    "except: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug corner - might not execture anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### older fits - comparison of validation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "conf_exps = [\n",
    "            f'V{i}' for i in range(0,10) # initially just gave the network fits version numbers V0 - V9\n",
    "          ]\n",
    "\n",
    "def find_weights(fn):\n",
    "    return fn[-3:] == '.pt'\n",
    "dims = (J+1) * np.ones(len(conf_exps))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for i, dat in enumerate(zip(conf_exps, dims)):\n",
    "    exp_id, dim = dat\n",
    "    save_dir = res_dir + 'models/' + exp_id + '/'\n",
    "\n",
    "\n",
    "    #plt.subplot(1,2,1)\n",
    "    try:\n",
    "        training_outputs = np.load(save_dir + '_training_outputs' + '.npy', allow_pickle=True)[()]\n",
    "        training_loss, validation_loss = training_outputs['training_loss'], training_outputs['validation_loss']\n",
    "        plt.semilogy(validation_loss, label=exp_id + f' ({dim}D)')\n",
    "    except:\n",
    "        plt.semilogy(1., label=exp_id + f' ({dim}D)')            \n",
    "    plt.title('training')\n",
    "\n",
    "plt.ylabel('validation error')\n",
    "plt.legend()\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "plt.figure(figsize=(16,4))\n",
    "cellText = np.hstack((np.array(conf_exps).reshape(-1,1), np.around(RMSEall,2)))\n",
    "collabel=('experiment', f'RMSE {lead_time}h, z 500', f'RMSE {lead_time}h, t 850')\n",
    "plt.axis('tight')\n",
    "plt.axis('off')\n",
    "plt.table(cellText=cellText,colLabels=collabel,loc='center')\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T_burnin = 10000\n",
    "out_model = model_simulate(y0=dg_train[T_burnin].copy(), T=T_)#.reshape(-1, K*(J+1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(J+1):\n",
    "    plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(2,) ))[:,i], \n",
    "             'b--')\n",
    "plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(2,) ))[:,0], 'k', linewidth=2,\n",
    "         label='slow variables')\n",
    "plt.semilogy(-1, 1, 'b--', label=f'fast variables (J={str(J)})')\n",
    "plt.axis([0,20,0.0000001, 0.5])\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('error over iterations, per variable type')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for i in range(J+1):\n",
    "    plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(2,) ))[:,i], \n",
    "             'b--')\n",
    "plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(2,) ))[:,0], 'k', linewidth=2,\n",
    "         label='slow variables')\n",
    "plt.semilogy(-1, 1, 'b--', label=f'fast variables (J={str(J)})')\n",
    "plt.axis([0,1300,0.0000001, 1000])\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('error over iterations, per variable type')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_burnin = 10000\n",
    "out_model = model_simulate(y0=dg_train[T_burnin].copy(), T=T_)#.reshape(-1, K*(J+1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(K):\n",
    "    plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(1,) ))[:,i], \n",
    "             'b--')\n",
    "plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(1,) ))[:,0], 'k', linewidth=2,\n",
    "         label='slow variables')\n",
    "plt.semilogy(-1, 1, 'b--', label=f'fast variables (J={str(J)})')\n",
    "plt.axis([0,20,0.0000001, 0.5])\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('error over iterations, per variable type')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for i in range(K):\n",
    "    plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(1,) ))[:,i], \n",
    "             'b--')\n",
    "plt.semilogy(np.arange(1, T_+1), (np.mean( (out_model[1:] - dg_train[np.arange(1,T_+1)+ T_burnin])**2, axis=(1,) ))[:,0], 'k', linewidth=2,\n",
    "         label='slow variables')\n",
    "plt.semilogy(-1, 1, 'b--', label=f'fast variables (J={str(J)})')\n",
    "plt.axis([0,1300,0.0000001, 1000])\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('error over iterations, per variable type')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 10000\n",
    "plt.plot((dg_train.mean_in + dg_train.std_in * dg_train[t][0,:,:]).reshape(K*(J+1)) - out[t])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 5000\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(dg_train[t+0].flatten(), label='t=0')\n",
    "plt.plot(dg_train[t+1].flatten(), label='t=1')\n",
    "plt.plot(model_simulate(y0=dg_train[t+0].copy(), T=1)[-1,:,:].flatten(), 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 10000\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(dg_train[t+1].flatten() - dg_train[t+0].flatten(), label='sim')\n",
    "plt.plot(model_simulate(y0=dg_train[t+0].copy(), T=1)[-1,:,:].flatten()  - dg_train[t+0].flatten(), label='model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [0, 100, 1000, 10000]:\n",
    "    plt.plot(model_simulate(y0=dg_train[t+0].copy(), T=1)[-1,:,:].flatten()  - dg_train[t+1].flatten(), label='model')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.semilogy(np.std(np.diff(dg_train[np.arange(T_+1)+ T_burnin].reshape(-1,(J+1)*K), axis=0), axis=0))\n",
    "plt.xlabel('variable ID (slow: first K=36)')\n",
    "plt.ylabel('std')\n",
    "plt.title('variability of 1-step temporal differences')\n",
    "plt.axis([0, 397, 0.001, 0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vmin, vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "T_burnin = 10000\n",
    "T_ = 10000\n",
    "plt.imshow(dg_train[np.arange(T_+1)+ T_burnin].reshape(-1,(J+1)*K).T, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dg_train[np.arange(T_+1)+ T_burnin][:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "T_burnin = 10000\n",
    "T_ = 10000\n",
    "plt.imshow(dg_train[np.arange(T_+1)+ T_burnin][:,:,0].reshape(-1,J+1).T, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,9))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(dg_train[np.arange(100)+T_burnin].reshape(100,-1).T - dg_train[T_burnin].reshape(-1,1), aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('numerical simulation, differences to yo')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(out_model[:100].reshape(100,-1).T - dg_train[T_burnin].reshape(-1,1), aspect='auto')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('location')\n",
    "plt.title('model-reconstructed simulation, differences to yo')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from L96_emulator.dataset import DatasetRelPred\n",
    "dg_train = DatasetRelPred(data=out, J=J, offset=temporal_offset, normalize=True, \n",
    "                          start=T_burnin, \n",
    "                          end=int(np.floor(out.shape[0]*0.8)))\n",
    "dg_val   = DatasetRelPred(data=out, J=J, offset=temporal_offset, normalize=True, \n",
    "                          start=int(np.ceil(out.shape[0]*0.8)), \n",
    "                          end=int(np.floor(out.shape[0]*0.9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct = 0\n",
    "s = np.zeros((474000, 11, 36))\n",
    "for batch in dg_train:\n",
    "    X,Y = batch\n",
    "    #print(X.shape, Y.shape)\n",
    "    \n",
    "    s[ct] = Y.copy()\n",
    "    ct += 1\n",
    "    if ct > 1000:\n",
    "        pass #break\n",
    "m = np.mean(s, axis=(0,2))\n",
    "s = np.std(s, axis=(0,2))\n",
    "print(m, s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
