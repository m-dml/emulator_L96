{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Build & evaluate an Emulator\n",
    "\n",
    "Given a dynamical system $F: x_t \\rightarrow x_{t_1} := F(x_t)$, we want to learn an emulator $G \\approx F$ as a neural network from $F$-sampled trajectories.\n",
    "\n",
    "Evaluate the quality of $G$ using:\n",
    "- L2 or other error metric on 1-step updates\n",
    "- L2 or other metric on longer rollouts\n",
    "- Compare Lyapunov spectrum to original model\n",
    "- Compare PSD etc. to original model\n",
    "For each of these metrics, there are baselines one can compare to from the literature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import L96sim\n",
    "\n",
    "from L96_emulator.util import dtype, dtype_np, device\n",
    "\n",
    "res_dir = '/gpfs/work/nonnenma/results/emulators/L96/'\n",
    "data_dir = '/gpfs/work/nonnenma/data/emulators/L96/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick a (trained) emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.run import setup\n",
    "\n",
    "exp_id = 24\n",
    "\n",
    "exp_names = os.listdir('experiments/')   \n",
    "conf_exp = exp_names[np.where(np.array([name[:2] for name in exp_names])==str(exp_id))[0][0]][:-4]\n",
    "\n",
    "args = setup(conf_exp=f'experiments/{conf_exp}.yml')\n",
    "args.pop('conf_exp')\n",
    "\n",
    "K,J = args['K'], args['J']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and instantiate the emulator model and an 'optimal' comparison available for L96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from L96_emulator.eval import load_model_from_exp_conf\n",
    "from L96_emulator.networks import named_network\n",
    "\n",
    "\n",
    "args['model_forwarder'] = 'rk4_default'\n",
    "model, _, training_outputs = load_model_from_exp_conf(res_dir, args)\n",
    "\n",
    "if not training_outputs is None:\n",
    "    training_loss, validation_loss = training_outputs['training_loss'], training_outputs['validation_loss']\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    seq_length = args['seq_length']\n",
    "    plt.semilogy(validation_loss, label=conf_exp+ f' ({seq_length * (J+1)}-dim)')\n",
    "    plt.title('training')\n",
    "    plt.ylabel('validation error')\n",
    "    plt.legend()\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.show()\n",
    "\n",
    "# upper bound: model re-implementation of L96 in torch (conv1d->pointwise_square->conv1d)\n",
    "model_ubo, model_forwarder_ubo =named_network(\n",
    "        model_name='MinimalConvNetL96',\n",
    "        n_input_channels=J+1,\n",
    "        n_output_channels=J+1,\n",
    "        seq_length=1,\n",
    "        **{'filters': [0],\n",
    "           'kernel_sizes': [4],\n",
    "           'init_net': 'analytical',\n",
    "           'K_net': K,\n",
    "           'J_net': J,\n",
    "           'dt_net': args['dt'],\n",
    "           'model_forwarder': 'rk4_default'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.eval import sortL96fromChannels, sortL96intoChannels\n",
    "dX_dt = np.empty(K*(J+1), dtype=dtype_np)\n",
    "i_trial = np.array([0, 1, 2])\n",
    "T_start = np.array([5000, 10000, 15000]) # grab initial states for rollout from long-running simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings for different solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.networks import Model_forwarder_predictorCorrector, Model_forwarder_rk4default\n",
    "\n",
    "dts = {Model_forwarder_predictorCorrector : 0.001,\n",
    "       Model_forwarder_rk4default : 0.01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load some data to get sensible test system state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.run import sel_dataset_class\n",
    "from L96_emulator.util import predictor_corrector, rk4_default, get_data\n",
    "\n",
    "spin_up_time, train_frac = args['spin_up_time'], args['train_frac']\n",
    "normalize_data = bool(args['normalize_data'])\n",
    "T, N_trials, dt = args['T'], args['N_trials'], args['dt']\n",
    "\n",
    "out, _ = get_data(K=K, J=J, T=T, dt=dt, N_trials=N_trials, F=10., h=1., b=10., c=10., \n",
    "                  resimulate=False, solver=rk4_default,\n",
    "                  save_sim=False, data_dir=data_dir)\n",
    "\n",
    "\n",
    "prediction_task = 'state'\n",
    "lead_time = 1\n",
    "DatasetClass = sel_dataset_class(prediction_task=prediction_task, N_trials=N_trials)\n",
    "dg_train = DatasetClass(data=out, J=J, offset=lead_time, normalize=normalize_data, \n",
    "                   start=int(spin_up_time/dt), \n",
    "                   end=int(np.floor(T/dt*train_frac)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up ground-truth simulator code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96sim.L96_base import f1, f2, pf2\n",
    "\n",
    "F, h, b, c = 10., 1., 10., 10.\n",
    "\n",
    "if J > 0:\n",
    "    def fun(t, x):\n",
    "        return f2(x, F, h, b, c, dX_dt, K, J)\n",
    "else:\n",
    "    def fun(t, x):\n",
    "        return f1(x, F, dX_dt, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## direct error on rhs of diff.eq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEs = np.zeros(len(T_start))\n",
    "MSEs_ubo = np.zeros(len(T_start))\n",
    "\n",
    "print('\\n')\n",
    "print('MSEs are on differential equation !')\n",
    "print('\\n')\n",
    "\n",
    "for i in range(len(T_start)): # diff.eq. implementaion in numpy cannot necessarily handle parallel solving\n",
    "    inputs = out[i_trial[i], T_start[i]] if N_trials > 1 else out[T_start[i]]\n",
    "    inputs_torch = torch.as_tensor(sortL96intoChannels(np.atleast_2d(inputs.copy()),J=J),dtype=dtype,device=device)\n",
    "\n",
    "    out_np = fun(0., inputs)\n",
    "    out_model = model.forward(inputs_torch).detach().cpu().numpy()\n",
    "    out_ubo = model_ubo.forward(inputs_torch).detach().cpu().numpy()\n",
    "    \n",
    "    MSEs[i] = ((out_np - sortL96fromChannels(out_model))**2).mean()\n",
    "    MSEs_ubo[i] = ((out_np - sortL96fromChannels(out_ubo))**2).mean()\n",
    "\n",
    "print('MSEs              ', MSEs)\n",
    "print('MSEs - upper bound', MSEs_ubo)\n",
    "\n",
    "print('\\n')\n",
    "print('MSEs (* dt)              ', MSEs*dt**2)\n",
    "print('MSEs (* dt) - upper bound', MSEs_ubo*dt**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-step integration error for different solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.networks import Model_forwarder_predictorCorrector, Model_forwarder_rk4default\n",
    "import torch \n",
    "\n",
    "print('\\n')\n",
    "print('MSEs are on system state !')\n",
    "print('\\n')\n",
    "\n",
    "MSEs = np.zeros(len(T_start))\n",
    "MSEs_ubo = np.zeros(len(T_start))\n",
    "\n",
    "class Torch_solver(torch.nn.Module):\n",
    "    # numerical solver (from numpy/numba/Julia)\n",
    "    def __init__(self, fun):\n",
    "        self.fun = fun\n",
    "    def forward(self, x):\n",
    "        x = sortL96fromChannels(x.detach().cpu().numpy()).flatten()\n",
    "        return sortL96intoChannels(np.atleast_2d(fun(0., x)), J=J)\n",
    "\n",
    "for MFWD in [Model_forwarder_predictorCorrector, Model_forwarder_rk4default]:\n",
    "    model_forwarder_np = MFWD(Torch_solver(fun), \n",
    "                              dt=dts[MFWD])\n",
    "    model_forwarder = MFWD(model=model, dt=dts[MFWD])\n",
    "    model_forwarder_ubo = MFWD(model=model_ubo, dt=dts[MFWD])\n",
    "\n",
    "    MSEs = np.zeros(len(T_start))\n",
    "    for i in range(len(T_start)):\n",
    "        inputs = out[i_trial[i], T_start[i]] if N_trials > 1 else out[T_start[i]]\n",
    "        inputs_torch = torch.as_tensor(sortL96intoChannels(np.atleast_2d(inputs.copy()),J=J),\n",
    "                                       dtype=dtype,device=device)\n",
    "\n",
    "        out_np = model_forwarder_np(inputs_torch)\n",
    "        out_model = model_forwarder(inputs_torch)\n",
    "        out_ubo = model_forwarder_ubo(inputs_torch)\n",
    "\n",
    "        MSEs[i] = ((out_np - out_model)**2).mean().detach().cpu().numpy()\n",
    "        MSEs_ubo[i] = ((out_np - out_ubo)**2).mean().detach().cpu().numpy()\n",
    "\n",
    "    print('\\n')\n",
    "    print(f'solver {MFWD}, dt = {dts[MFWD]}')\n",
    "    print('\\n')\n",
    "\n",
    "    print('MSEs              ', MSEs)\n",
    "    print('MSEs - upper bound', MSEs_ubo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-step integration error (rollout error) for different solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from L96_emulator.eval import get_rollout_fun, plot_rollout\n",
    "\n",
    "print('\\n')\n",
    "print('MSEs are on system state !')\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "MTU = 2 # rollout time in time units, should be rough estimate of first Lyapunov exponent\n",
    "\n",
    "for i in range(len(T_start)):\n",
    "    print(f'integrating for starting point {i+1} / {len(T_start)}')\n",
    "    for MFWD in [Model_forwarder_predictorCorrector, Model_forwarder_rk4default]:\n",
    "\n",
    "        print(f'solver {MFWD}, dt = {dts[MFWD]}')\n",
    "        T_dur = int(MTU/dts[MFWD])\n",
    "\n",
    "        model_forwarder_np = MFWD(Torch_solver(fun), \n",
    "                                  dt=dts[MFWD])\n",
    "        model_forwarder = MFWD(model=model, dt=dts[MFWD])\n",
    "        model_forwarder_ubo = MFWD(model=model_ubo, dt=dts[MFWD])\n",
    "\n",
    "        model_simulate = get_rollout_fun(dg_train, model_forwarder, prediction_task)\n",
    "        ubo_simulate = get_rollout_fun(dg_train, model_forwarder_ubo, prediction_task)\n",
    "        np_simulate = get_rollout_fun(dg_train, model_forwarder_np, prediction_task)\n",
    "\n",
    "        out_np = np_simulate(y0=dg_train[T_start[i]].copy(), \n",
    "                             dy0=dg_train[T_start[i]]-dg_train[T_start[i]-dg_train.offset],\n",
    "                             n_steps=T_dur)\n",
    "        out_np = sortL96fromChannels(out_np * dg_train.std + dg_train.mean)\n",
    "        out_model = model_simulate(y0=dg_train[T_start[i]].copy(), \n",
    "                                   dy0=dg_train[T_start[i]]-dg_train[T_start[i]-dg_train.offset],\n",
    "                                   n_steps=T_dur)\n",
    "        out_model = sortL96fromChannels(out_model * dg_train.std + dg_train.mean)\n",
    "\n",
    "        out_ubo = ubo_simulate(y0=dg_train[T_start[i]].copy(), \n",
    "                                   dy0=dg_train[T_start[i]]-dg_train[T_start[i]-dg_train.offset],\n",
    "                                   n_steps=T_dur)\n",
    "        out_ubo = sortL96fromChannels(out_ubo * dg_train.std + dg_train.mean)\n",
    "\n",
    "        fig = plot_rollout(out_np, out_model, out_comparison=out_ubo, n_start=0, n_steps=T_dur, K=K)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.legend(['trained model', '(only slow vars)', 'upper-bound model', '(only slow vars)'])\n",
    "        plt.suptitle('integration scheme: ' + str(MFWD))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tbd: compare Lyapunov spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeah, hf fiddling the pytorch model into Julia..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tbd: check long-term stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tbd: compare distribution of values (PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# share notebook results via html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --output-dir='/gpfs/home/nonnenma/projects/lab_coord/mdml_wiki/marcel/emulators' --to html eval_emulator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
