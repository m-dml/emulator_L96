{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import L96sim\n",
    "\n",
    "from L96_emulator.util import dtype, dtype_np, device\n",
    "\n",
    "res_dir = '/gpfs/work/nonnenma/results/emulators/L96/'\n",
    "data_dir = '/gpfs/work/nonnenma/data/emulators/L96/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulator evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from L96_emulator.run import setup, sel_dataset_class\n",
    "from L96_emulator.eval import sortL96fromChannels, sortL96intoChannels, load_model_from_exp_conf\n",
    "from L96_emulator.networks import named_network, Model_forwarder_predictorCorrector, Model_forwarder_rk4default\n",
    "from L96_emulator.util import predictor_corrector, rk4_default, get_data, as_tensor\n",
    "from L96sim.L96_base import f1, f2, pf2\n",
    "\n",
    "# experiments to use: \n",
    "\n",
    "# for one-level L96, K=40, F=8\n",
    "\n",
    "# reference (analytical) emulators:\n",
    "# dt=0.05  : exp_id=34 for minimal, exp_id=35 for bilinear net\n",
    "# dt=0.0125: exp_id=37 for minimal, exp_id=36 for bilinear net\n",
    "# full domain training: \n",
    "# dt=0.05  : exp_id=26 for minimal, exp_id=27 for bilinear net\n",
    "# dt=0.0125: exp_id=28 for minimal, exp_id=29 for bilinear net\n",
    "# local training:\n",
    "# K_local = 10, batch-size = 32\n",
    "# dt=0.05  : exp_id=30 for minimal, exp_id=31 for bilinear net\n",
    "# dt=0.0125: exp_id=32 for minimal, exp_id=33 for bilinear net\n",
    "# K_local = 1, batch-size = 32\n",
    "# dt=0.05  : exp_id=38 for minimal, exp_id=39 for bilinear net\n",
    "# K_local = 1, batch-size = 1\n",
    "# dt=0.05  : exp_id=40 for minimal, exp_id=41 for bilinear net\n",
    "\n",
    "# for one-level L96, K=36, F=10\n",
    "\n",
    "# full domain training: \n",
    "# dt=0.01  : exp_id=42 for minimal, exp_id=43 for bilinear net\n",
    "\n",
    "\n",
    "exp_ids = [34, 26, 37, 27, 65]\n",
    "exp_id_model_sorted = [np.arange(len(exp_ids))]\n",
    "model_names = ['emulator training']\n",
    "\n",
    "\n",
    "# initial one-level L96, K=40, F=8 with various degrees of locality: \n",
    "#exp_ids = [34, 26, 30, 38, 40, 35, 27, 31, 39, 41]\n",
    "#exp_id_model_sorted = [np.arange(0,5), np.arange(5,10)]\n",
    "#model_names = ['quadratic nonlinearity network', 'bilinear layer network']\n",
    "\n",
    "# 4x4 one-level L96, K=40, F=8 with various degrees of locality and batch-size\n",
    "#exp_ids = np.concatenate((np.arange(49, 61), np.arange(61, 65)))\n",
    "#exp_id_model_sorted=[np.arange(4), np.arange(4,8), np.arange(8,12), np.arange(12,16), ]\n",
    "#model_names=['batch-size 1', 'batch-size 4', 'batch-size 16', 'batch-size 64']\n",
    "\n",
    "#exp_ids = [42, 43, 44]\n",
    "#exp_id_model_sorted = [np.arange(len(exp_ids))]\n",
    "#model_names=['emulator training']\n",
    "\n",
    "\n",
    "all_lgnd = []\n",
    "all_models, all_model_forwarders, all_training_outputs = [], [], []\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "for exp_id in exp_ids:\n",
    "\n",
    "    exp_names = os.listdir('experiments/')   \n",
    "    conf_exp = exp_names[np.where(np.array([name[:2] for name in exp_names])==str(exp_id))[0][0]][:-4]\n",
    "\n",
    "    args = setup(conf_exp=f'experiments/{conf_exp}.yml')\n",
    "    args.pop('conf_exp')\n",
    "    args['model_forwarder'] = 'rk4_default'\n",
    "\n",
    "    K,J = args['K'], args['J']\n",
    "    assert args['dt_net'] == args['dt']\n",
    "\n",
    "    if J > 0:\n",
    "        F, h, b, c = 10., 1., 10., 10.\n",
    "    else:\n",
    "        h, b, c = 1., 10., 10.\n",
    "        F = 10. if K==36 else 8.\n",
    "\n",
    "    #exp_str = 'blnNet' if args['model_name']=='BilinearConvNetL96' else 'sqrNet'\n",
    "    if args['init_net']=='analytical':\n",
    "        exp_str = 'analytic'\n",
    "    else:\n",
    "        exp_str = 'localK'+str(args['K_local']) if args['loss_fun']=='local_mse' else 'fullDomain'\n",
    "        exp_str += '_bs'+str(args['batch_size'])\n",
    "        \n",
    "    all_lgnd.append(exp_str)\n",
    "\n",
    "    if args['padding_mode'] == 'valid':\n",
    "        print('switching from local training to global evaluation')\n",
    "        args['padding_mode'] = 'circular'\n",
    "    model, model_forwarder, training_outputs = load_model_from_exp_conf(res_dir, args)\n",
    "    all_models.append(model)\n",
    "    all_model_forwarders.append(model_forwarder)\n",
    "    all_training_outputs.append(training_outputs)\n",
    "\n",
    "    if not training_outputs is None:\n",
    "        seq_length = args['seq_length']\n",
    "        plt.semilogy(training_outputs['validation_loss'], label=all_lgnd[-1])\n",
    "\n",
    "all_lgnd = np.array(all_lgnd)\n",
    "plt.title('training')\n",
    "plt.ylabel('validation error')\n",
    "plt.legend()\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.show()\n",
    "\n",
    "dX_dt = np.empty(K*(J+1), dtype=dtype_np)\n",
    "dts = {Model_forwarder_predictorCorrector : args['dt']/10,\n",
    "       Model_forwarder_rk4default : args['dt']}\n",
    "\n",
    "spin_up_time, train_frac = args['spin_up_time'], args['train_frac']\n",
    "normalize_data = bool(args['normalize_data'])\n",
    "T, N_trials, dt = args['T'], args['N_trials'], args['dt']\n",
    "\n",
    "T = (1000)*dt + spin_up_time\n",
    "\n",
    "out, _ = get_data(K=K, J=J, T=T, dt=dt, N_trials=N_trials, F=F, h=h, b=b, c=c, \n",
    "                  resimulate=True, solver=rk4_default,\n",
    "                  save_sim=False, data_dir=data_dir)\n",
    "\n",
    "if J > 0:\n",
    "    def fun(t, x):\n",
    "        return f2(x, F, h, b, c, dX_dt, K, J)\n",
    "else:\n",
    "    def fun(t, x):\n",
    "        return f1(x, F, dX_dt, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [2,0,4]:\n",
    "    print('\\n\\n\\n')\n",
    "    print(all_models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_start = np.arange(int(spin_up_time/dt), int(T/dt)) # grab initial states for rollout from long-running simulations\n",
    "i_trial = np.random.choice(N_trials, size=T_start.shape)\n",
    "idx_show = np.arange(0,len(T_start)-1, len(T_start)//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSEs_tendencies = np.zeros((len(exp_ids), len(T_start)))\n",
    "\n",
    "print('\\n')\n",
    "print('MSEs are on differential equation (tendencies) !')\n",
    "print('\\n')\n",
    "\n",
    "for m_i, model in enumerate(all_models):\n",
    "    for i in range(len(T_start)): # diff.eq. implementaion in numpy cannot necessarily handle parallel solving\n",
    "        inputs = out[i_trial[i], T_start[i]] if N_trials > 1 else out[T_start[i]]\n",
    "        inputs_torch = as_tensor(sortL96intoChannels(np.atleast_2d(inputs.copy()),J=J))\n",
    "\n",
    "        out_np = fun(0., inputs)\n",
    "        out_model = model.forward(inputs_torch).detach().cpu().numpy()\n",
    "\n",
    "        RMSEs_tendencies[m_i,i] = np.sqrt(((out_np - sortL96fromChannels(out_model))**2).mean())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "for i in range(len(exp_id_model_sorted)):\n",
    "    plt.subplot(len(exp_id_model_sorted),2,1+2*i)\n",
    "    plt.semilogy(np.sort(RMSEs_tendencies[exp_id_model_sorted[i]],axis=1).T)\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xlabel('test data point (sorted)')\n",
    "    plt.title(model_names[i])\n",
    "    plt.legend(all_lgnd[exp_id_model_sorted[i]])\n",
    "    plt.subplot(len(exp_id_model_sorted),2,2+2*i)\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.boxplot(RMSEs_tendencies[exp_id_model_sorted[i]].T, labels=all_lgnd[exp_id_model_sorted[i]])\n",
    "    plt.title(model_names[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.networks import Model_forwarder_predictorCorrector, Model_forwarder_rk4default\n",
    "import torch \n",
    "\n",
    "print('\\n')\n",
    "print('MSEs are on system state !')\n",
    "print('\\n')\n",
    "\n",
    "MFWDs = [Model_forwarder_predictorCorrector, Model_forwarder_rk4default]\n",
    "RMSEs_states = np.zeros((len(MFWDs), len(exp_ids), len(T_start)))\n",
    "\n",
    "class Torch_solver(torch.nn.Module):\n",
    "    # numerical solver (from numpy/numba/Julia)\n",
    "    def __init__(self, fun):\n",
    "        self.fun = fun\n",
    "    def forward(self, x):\n",
    "        x = sortL96fromChannels(x.detach().cpu().numpy()).flatten()\n",
    "        return as_tensor(sortL96intoChannels(np.atleast_2d(self.fun(0., x)), J=J))\n",
    "\n",
    "    \n",
    "for mf_i, MFWD in enumerate(MFWDs):\n",
    "\n",
    "    print('\\n')\n",
    "    print(f'solver {MFWD}, dt = {dts[MFWD]}')\n",
    "    print('\\n')\n",
    "\n",
    "    model_forwarder_np = MFWD(Torch_solver(fun), dt=dts[MFWD])\n",
    "    \n",
    "    for m_i, model in enumerate(all_models):\n",
    "        \n",
    "        model_forwarder = MFWD(model=model, dt=dts[MFWD])\n",
    "        \n",
    "        for i in range(len(T_start)):\n",
    "            inputs = out[i_trial[i], T_start[i]] if N_trials > 1 else out[T_start[i]]\n",
    "            inputs_torch = as_tensor(sortL96intoChannels(np.atleast_2d(inputs.copy()),J=J))\n",
    "\n",
    "            out_np = model_forwarder_np(inputs_torch)\n",
    "            out_model = model_forwarder(inputs_torch)\n",
    "\n",
    "            RMSEs_states[mf_i, m_i, i] = np.sqrt(((out_np - out_model)**2).mean().detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(16,12))\n",
    "    for i in range(len(exp_id_model_sorted)):\n",
    "        plt.subplot(len(exp_id_model_sorted),2,1+2*i)\n",
    "        plt.semilogy(np.sort(RMSEs_states[mf_i][exp_id_model_sorted[i]],axis=1).T)\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.xlabel('test data point (sorted)')\n",
    "        plt.title(model_names[i])\n",
    "        plt.legend(all_lgnd[exp_id_model_sorted[i]])\n",
    "        plt.subplot(len(exp_id_model_sorted),2,2+2*i)\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.boxplot(RMSEs_states[mf_i][exp_id_model_sorted[i]].T, labels=all_lgnd[exp_id_model_sorted[i]])\n",
    "        plt.title(model_names[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=14\n",
    "plt.figure(figsize=(16,4))\n",
    "ax = plt.subplot(1,3,1)\n",
    "plt.text(0.5, 0.5, 'sketch', fontsize=fontsize)\n",
    "ax.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(RMSEs_states[-1].mean(axis=1).reshape(4,4), vmax=3e-6, cmap='cividis')\n",
    "plt.xlabel('local region size', fontsize=fontsize)\n",
    "plt.xticks(range(4), ['640', '160', '40', '10'], fontsize=fontsize)\n",
    "plt.ylabel('batch-size', fontsize=fontsize)\n",
    "plt.yticks(range(4), ['1', '4', '16', '64'], fontsize=fontsize)\n",
    "plt.colorbar()\n",
    "plt.title(r'RMSE on predicted $x_{t+\\Delta}$')\n",
    "for i in range(4):\n",
    "    plt.plot(np.array([-.5, .5])+i, np.array([-0.5, -0.5])+i, 'k--', linewidth=2)\n",
    "    plt.plot(np.array([.5, .5])+i, np.array([-.5, .5])+i, 'k--', linewidth=2)\n",
    "plt.plot([0.5, 3.5], [-0.5, -0.5], 'k--', linewidth=2)\n",
    "plt.plot([3.5, 3.5], [-0.5, 2.5], 'k--', linewidth=2)\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "batch_sizes = [1, 1, 1, 1, 4, 4, 4, 4, 16, 16, 16, 16, 64, 64, 64, 64]\n",
    "region_sizes = [640, 160, 40, 10, 640, 160, 40, 10, 640, 160, 40, 10, 640, 160, 40, 10]\n",
    "plt.semilogx([640, 640], [0.1e-6, 2e-6], 'k--', linewidth=2.)\n",
    "for i in range(len(RMSEs_states[-1])):\n",
    "    plt.semilogx(batch_sizes[i]*region_sizes[i], RMSEs_states[-1][i].mean(), 'b.', markersize=8.0)\n",
    "plt.xlabel('locations per minibatch', fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(np.array([0.5, 1., 1.5, 2.])*1e-6, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.title(r'RMSE on predicted $x_{t+\\Delta}$', fontsize=fontsize)\n",
    "plt.ylabel('RMSE', fontsize=fontsize)\n",
    "\n",
    "plt.savefig(res_dir + 'figs/emulator_local.pdf', bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.networks import Model_forwarder_predictorCorrector, Model_forwarder_rk4default\n",
    "from L96_emulator.util import calc_jakobian_onelevelL96_tendencies, calc_jakobian_rk4, get_jacobian_torch\n",
    "import torch \n",
    "\n",
    "def model_np(inputs):\n",
    "    return fun(0., inputs).copy()\n",
    "\n",
    "print('\\n')\n",
    "print('MSEs are on system state !')\n",
    "print('\\n')\n",
    "\n",
    "MFWDs = [Model_forwarder_rk4default]\n",
    "L2_jakobians = np.zeros((len(MFWDs), len(exp_ids), len(T_start)))\n",
    "\n",
    "  \n",
    "for mf_i, MFWD in enumerate(MFWDs):\n",
    "\n",
    "    print('\\n')\n",
    "    print(f'solver {MFWD}, dt = {dts[MFWD]}')\n",
    "    print('\\n')\n",
    "    \n",
    "    for m_i, model in enumerate(all_models):\n",
    "        \n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        model_forwarder = MFWD(model=model, dt=dts[MFWD])\n",
    "        print('\\n')\n",
    "        print(f'model forwarder for {model}')\n",
    "        print('\\n')\n",
    "        \n",
    "        for i in range(len(T_start)):\n",
    "            inputs = out[i_trial[i], T_start[i]] if N_trials > 1 else out[T_start[i]]\n",
    "            inputs_torch = as_tensor(sortL96intoChannels(np.atleast_2d(inputs.copy()),J=J))\n",
    "            inputs_torch.requires_grad = True\n",
    "            \n",
    "            #J_np = calc_jakobian_onelevelL96_tendencies(inputs, n=K)\n",
    "            J_np = calc_jakobian_rk4(inputs, calc_f=model_np, \n",
    "                         calc_J_f=calc_jakobian_onelevelL96_tendencies, dt=dt, n=K)\n",
    "\n",
    "            J_torch = get_jacobian_torch(model_forwarder, inputs=inputs_torch, n=K)\n",
    "\n",
    "            L2_jakobians[mf_i, m_i, i] = np.sqrt(((J_np - J_torch)**2).sum())\n",
    "\n",
    "    plt.figure(figsize=(16,12))\n",
    "    for i in range(len(exp_id_model_sorted)):\n",
    "        plt.subplot(2,2,1+2*i)\n",
    "        plt.semilogy(np.sort(L2_jakobians[mf_i][exp_id_model_sorted[i]],axis=1).T)\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.xlabel('test data point (sorted)')\n",
    "        plt.title(model_names[i])\n",
    "        plt.legend(all_lgnd[exp_id_model_sorted[i]])\n",
    "        plt.subplot(2,2,2+2*i)\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.boxplot(L2_jakobians[mf_i][exp_id_model_sorted[i]].T, labels=all_lgnd[exp_id_model_sorted[i]])\n",
    "        plt.title(model_names[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.networks import Model_forwarder_predictorCorrector, Model_forwarder_rk4default\n",
    "from L96_emulator.util import calc_jakobian_onelevelL96_tendencies, calc_jakobian_rk4, get_jacobian_torch\n",
    "import torch \n",
    "\n",
    "def model_np(inputs):\n",
    "    return fun(0., inputs).copy()\n",
    "\n",
    "print('\\n')\n",
    "print('MSEs are on system state !')\n",
    "print('\\n')\n",
    "\n",
    "MFWDs = [Model_forwarder_rk4default]\n",
    "L2_jakobians_tendencies = np.zeros((len(MFWDs), len(exp_ids), len(T_start)))\n",
    "\n",
    "  \n",
    "for mf_i, MFWD in enumerate(MFWDs):\n",
    "\n",
    "    print('\\n')\n",
    "    print(f'solver {MFWD}, dt = {dts[MFWD]}')\n",
    "    print('\\n')\n",
    "    \n",
    "    for m_i, model in enumerate(all_models):\n",
    "        \n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        model_forwarder = MFWD(model=model, dt=dts[MFWD])\n",
    "        print('\\n')\n",
    "        print(f'model forwarder for {model}')\n",
    "        print('\\n')\n",
    "        \n",
    "        for i in range(len(T_start)):\n",
    "            inputs = out[i_trial[i], T_start[i]] if N_trials > 1 else out[T_start[i]]\n",
    "            inputs_torch = as_tensor(sortL96intoChannels(np.atleast_2d(inputs.copy()),J=J))\n",
    "            inputs_torch.requires_grad = True\n",
    "            \n",
    "            J_np = calc_jakobian_onelevelL96_tendencies(inputs, n=K)\n",
    "            #J_np = calc_jakobian_rk4(inputs, calc_f=model_np, \n",
    "            #             calc_J_f=calc_jakobian_onelevelL96_tendencies, dt=dt, n=K)\n",
    "\n",
    "            J_torch = get_jacobian_torch(model, inputs=inputs_torch, n=K)\n",
    "\n",
    "            L2_jakobians_tendencies[mf_i, m_i, i] = np.sqrt(((J_np - J_torch)**2).sum())\n",
    "\n",
    "    plt.figure(figsize=(16,12))\n",
    "    for i in range(len(exp_id_model_sorted)):\n",
    "        plt.subplot(2,2,1+2*i)\n",
    "        plt.semilogy(np.sort(L2_jakobians_tendencies[mf_i][exp_id_model_sorted[i]],axis=1).T)\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.xlabel('test data point (sorted)')\n",
    "        plt.title(model_names[i])\n",
    "        plt.legend(all_lgnd[exp_id_model_sorted[i]])\n",
    "        plt.subplot(2,2,2+2*i)\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.boxplot(L2_jakobians_tendencies[mf_i][exp_id_model_sorted[i]].T, labels=all_lgnd[exp_id_model_sorted[i]])\n",
    "        plt.title(model_names[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_panels = 4\n",
    "plt.figure(figsize=((16,4)))\n",
    "\n",
    "model_labels = ['analytic', 'trained', 'analytic',  'trained', 'trained']\n",
    "\n",
    "plt.subplot(1,n_panels,1)\n",
    "plt.ylabel('RMSE')\n",
    "plt.boxplot(RMSEs_tendencies.T, labels=model_labels)\n",
    "plt.gcf().text(0.15, 0.02, 'sqrNet')\n",
    "plt.gcf().text(0.23, 0.02, 'bilinNet')\n",
    "plt.title('tendencies', y=1.05)\n",
    "plt.yticks(np.array([0, 2, 4, 6])*1e-6)\n",
    "\n",
    "plt.subplot(1,n_panels,2)\n",
    "plt.ylabel('RMSE')\n",
    "plt.boxplot(RMSEs_states[1].T, labels=model_labels)\n",
    "plt.gcf().text(0.35, 0.02, 'sqrNet')\n",
    "plt.gcf().text(0.43, 0.02, 'bilinNet')\n",
    "plt.title(r'state prediction (RK4, $\\Delta=0.05$)', y=1.05)\n",
    "plt.yticks(np.array([0, 1, 2, 3])*1e-7)\n",
    "\n",
    "plt.subplot(1,n_panels,3)\n",
    "plt.ylabel('RMSE')\n",
    "plt.boxplot(RMSEs_states[0].T, labels=model_labels)\n",
    "plt.gcf().text(0.56, 0.02, 'sqrNet')\n",
    "plt.gcf().text(0.64, 0.02, 'bilinNet')\n",
    "plt.title(r'state prediction (pred-corr, $\\Delta=0.005$)', y=1.05)\n",
    "plt.yticks(np.array([0, 0.5, 1, 1.5])*1e-7)\n",
    "\n",
    "plt.subplot(1,n_panels,4)\n",
    "plt.ylabel('Frobenius Norm')\n",
    "plt.boxplot(L2_jakobians[0].T, labels=model_labels)\n",
    "plt.gcf().text(0.75, 0.02, 'sqrNet')\n",
    "plt.gcf().text(0.85, 0.02, 'bilinNet')\n",
    "plt.title(r'Jakobian (RK4, $\\Delta=0.05$)', y=1.05)\n",
    "plt.yticks(np.array([2, 3, 4])*1e-7)\n",
    "plt.savefig(res_dir + 'figs/emulator_eval.pdf', bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_panels = 4\n",
    "fontsize = 14\n",
    "\n",
    "plt.figure(figsize=((10,8)))\n",
    "\n",
    "model_labels = ['analytic', 'trained', 'analytic',  'trained', 'trained']\n",
    "clrs = ['cyan', 'blue', 'red', 'orange', 'green']\n",
    "\n",
    "ax = plt.subplot(n_panels//2,n_panels//2,1)\n",
    "RMSEs = RMSEs_tendencies\n",
    "plt.ylabel('RMSE', fontsize=fontsize)\n",
    "plt.bar(np.arange(len(model_labels)), RMSEs.mean(axis=1), color=clrs)\n",
    "for i in range(len(model_labels)):\n",
    "    plt.plot(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             'k', linewidth=1.5)\n",
    "#plt.gcf().text(0.15, 0.02, 'sqrNet', fontsize=fontsize)\n",
    "#plt.gcf().text(0.23, 0.02, 'bilinNet', fontsize=fontsize)\n",
    "plt.xticks(np.arange(len(model_labels)), [], fontsize=fontsize)\n",
    "plt.title('tendencies', y=1.05, fontsize=fontsize)\n",
    "plt.yticks(np.array([0, 2, 4])*1e-6, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax = plt.subplot(n_panels//2,n_panels//2,2)\n",
    "RMSEs = RMSEs_states[1]\n",
    "plt.ylabel('RMSE', fontsize=fontsize)\n",
    "plt.bar(np.arange(len(model_labels)), RMSEs.mean(axis=1), color=clrs)\n",
    "for i in range(len(model_labels)):\n",
    "    plt.plot(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             'k', linewidth=1.5)\n",
    "#plt.gcf().text(0.35, 0.02, 'sqrNet', fontsize=fontsize)\n",
    "#plt.gcf().text(0.43, 0.02, 'bilinNet', fontsize=fontsize)\n",
    "plt.xticks(np.arange(len(model_labels)), [], fontsize=fontsize)\n",
    "plt.title(r'state prediction (RK4, $\\Delta=0.05$)', y=1.05, fontsize=fontsize)\n",
    "plt.yticks(np.array([0, 1, 2])*1e-7, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "\"\"\"\n",
    "ax = plt.subplot(1,n_panels,3)\n",
    "RMSEs = RMSEs_states[0]\n",
    "plt.ylabel('RMSE')\n",
    "plt.bar(np.arange(len(model_labels)), RMSEs.mean(axis=1), color=clrs)\n",
    "for i in range(len(model_labels)):\n",
    "    plt.plot(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             'k', linewidth=1.5)\n",
    "plt.gcf().text(0.56, 0.02, 'sqrNet')\n",
    "plt.gcf().text(0.64, 0.02, 'bilinNet')\n",
    "plt.xticks(np.arange(len(model_labels)), model_labels)\n",
    "plt.title(r'state prediction (pred-corr, $\\Delta=0.005$)', y=1.05)\n",
    "plt.yticks(np.array([0, 0.5, 1, 1.5])*1e-7)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\"\"\"\n",
    "\n",
    "ax = plt.subplot(n_panels//2,n_panels//2,3)\n",
    "RMSEs = L2_jakobians_tendencies[0]\n",
    "plt.ylabel('Frobenius Norm', fontsize=fontsize)\n",
    "plt.bar(np.arange(len(model_labels)), RMSEs.mean(axis=1), color=clrs)\n",
    "for i in range(len(model_labels)):\n",
    "    plt.plot(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             'k', linewidth=1.5)\n",
    "plt.gcf().text(0.18, 0.05, 'sqrNet', fontsize=fontsize)\n",
    "plt.gcf().text(0.35, 0.05, 'bilinNet', fontsize=fontsize)\n",
    "plt.title(r'Jakobian (tendencies)',  fontsize=fontsize)\n",
    "plt.xticks(np.arange(len(model_labels)), model_labels, fontsize=fontsize)\n",
    "plt.yticks(np.array([1, 2, 3])*1e-6, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "ax = plt.subplot(n_panels//2,n_panels//2,4)\n",
    "RMSEs = L2_jakobians[0]\n",
    "plt.ylabel('Frobenius Norm', fontsize=fontsize)\n",
    "plt.bar(np.arange(len(model_labels)), RMSEs.mean(axis=1), color=clrs)\n",
    "for i in range(len(model_labels)):\n",
    "    plt.plot(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             'k', linewidth=1.5)\n",
    "plt.gcf().text(0.60, 0.05, 'sqrNet', fontsize=fontsize)\n",
    "plt.gcf().text(0.77, 0.05, 'bilinNet', fontsize=fontsize)\n",
    "plt.title(r'Jakobian (RK4, $\\Delta=0.05$)', fontsize=fontsize)\n",
    "plt.xticks(np.arange(len(model_labels)), model_labels, fontsize=fontsize)\n",
    "plt.yticks(np.array([1, 2, 3])*1e-7, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "#plt.savefig(res_dir + 'figs/emulator_eval.pdf', bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_panels = 4\n",
    "fontsize = 14\n",
    "\n",
    "plt.figure(figsize=((12,8)))\n",
    "\n",
    "model_labels = ['analytic', 'trained', 'analytic',  'trained', 'trained']\n",
    "clrs = ['cyan', 'blue', 'red', 'orange', 'green']\n",
    "\n",
    "ax = plt.subplot(n_panels//2,n_panels//2,1)\n",
    "RMSEs = RMSEs_tendencies\n",
    "for i in range(len(model_labels)):\n",
    "    plt.semilogy(i*np.ones(2)+np.array([-0.5,0.5]), \n",
    "             RMSEs.mean(axis=1)[i]*np.ones(2),\n",
    "             color=clrs[i], linewidth=1.5)\n",
    "    plt.semilogy(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             color='k', linewidth=1.5)\n",
    "plt.xticks(np.arange(len(model_labels)), [], fontsize=fontsize)\n",
    "plt.title('tendencies', y=1.05, fontsize=fontsize)\n",
    "plt.ylabel('RMSE', fontsize=fontsize)\n",
    "#plt.yticks(np.array([0, 2, 4])*1e-6, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax = plt.subplot(n_panels//2,n_panels//2,2)\n",
    "RMSEs = RMSEs_states[1]\n",
    "for i in range(len(model_labels)):\n",
    "    plt.semilogy(i*np.ones(2)+np.array([-0.5,0.5]), \n",
    "             RMSEs.mean(axis=1)[i]*np.ones(2),\n",
    "             color=clrs[i], linewidth=1.5)\n",
    "    plt.semilogy(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             color='k', linewidth=1.5)\n",
    "plt.xticks(np.arange(len(model_labels)), [], fontsize=fontsize)\n",
    "plt.title(r'state prediction (RK4, $\\Delta=0.05$)', y=1.05, fontsize=fontsize)\n",
    "plt.ylabel('RMSE', fontsize=fontsize)\n",
    "#plt.yticks(np.array([0, 1, 2])*1e-7, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax = plt.subplot(n_panels//2,n_panels//2,3)\n",
    "RMSEs = L2_jakobians_tendencies[0]\n",
    "for i in range(len(model_labels)):\n",
    "    plt.semilogy(i*np.ones(2)+np.array([-0.5,0.5]), \n",
    "             RMSEs.mean(axis=1)[i]*np.ones(2),\n",
    "             color=clrs[i], linewidth=1.5)\n",
    "    plt.semilogy(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             color='k', linewidth=1.5)\n",
    "plt.title(r'Jakobian (tendencies)',  fontsize=fontsize)\n",
    "plt.xticks(np.arange(len(model_labels)), model_labels, fontsize=fontsize)\n",
    "#plt.yticks(np.array([1, 2, 3])*1e-6, fontsize=fontsize)\n",
    "plt.ylabel('Frobenius Norm', fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "ax = plt.subplot(n_panels//2,n_panels//2,4)\n",
    "RMSEs = L2_jakobians[0]\n",
    "for i in range(len(model_labels)):\n",
    "    plt.semilogy(i*np.ones(2)+np.array([-0.5,0.5]), \n",
    "             RMSEs.mean(axis=1)[i]*np.ones(2),\n",
    "             color=clrs[i], linewidth=1.5)\n",
    "    plt.semilogy(i*np.ones(2), \n",
    "             RMSEs.mean(axis=1)[i]+RMSEs.std(axis=1)[i]*np.array([-1,1]),\n",
    "             color='k', linewidth=1.5)\n",
    "plt.title(r'Jakobian (RK4, $\\Delta=0.05$)', fontsize=fontsize)\n",
    "plt.xticks(np.arange(len(model_labels)), model_labels, fontsize=fontsize)\n",
    "plt.ylabel('Frobenius Norm', fontsize=fontsize)\n",
    "#plt.yticks(np.array([1, 2, 3])*1e-7, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#\"\"\"\n",
    "\n",
    "plt.gcf().text(0.18, 0.05, 'sqrNet', fontsize=fontsize)\n",
    "plt.gcf().text(0.30, 0.05, 'bilinNet', fontsize=fontsize)\n",
    "plt.gcf().text(0.40, 0.05, 'deepNet', fontsize=fontsize)\n",
    "plt.gcf().text(0.60, 0.05, 'sqrNet', fontsize=fontsize)\n",
    "plt.gcf().text(0.72, 0.05, 'bilinNet', fontsize=fontsize)\n",
    "plt.gcf().text(0.82, 0.05, 'deepNet', fontsize=fontsize)\n",
    "\n",
    "\n",
    "plt.savefig(res_dir + 'figs/emulator_eval.pdf', bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4D-Var results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.run import setup\n",
    "from L96_emulator.run_DA import setup_4DVar\n",
    "from L96_emulator.likelihood import ObsOp_identity, ObsOp_subsampleGaussian, ObsOp_rotsampleGaussian\n",
    "from L96_emulator.data_assimilation import GenModel, get_model, as_tensor\n",
    "from L96_emulator.util import sortL96fromChannels, sortL96intoChannels\n",
    "import torch\n",
    "\n",
    "clrs, lgnd = ['w', 'b', 'c', 'g', 'y', 'r', 'm', 'k'], []\n",
    "\n",
    "def get_analysis_rmses_4DVar_exp(exp_ids, ifplot=False):\n",
    "\n",
    "    rmses_total = np.zeros(len(exp_ids))\n",
    "    win_lens = np.zeros(len(exp_ids))\n",
    "\n",
    "    if ifplot:\n",
    "        plt.figure(figsize=(16,6))\n",
    "        plt.subplot(1,3,1)\n",
    "        for clr in clrs:\n",
    "            plt.plot(-100, -1, 'o-', color=clr, linewidth=2.5)    \n",
    "\n",
    "    for eid, exp_id in enumerate(exp_ids):\n",
    "\n",
    "        exp_names = os.listdir('experiments_DA/')   \n",
    "        conf_exp = exp_names[np.where(np.array([name[:2] for name in exp_names])==str(exp_id))[0][0]][:-4]\n",
    "        args = setup_4DVar(conf_exp=f'experiments_DA/{conf_exp}.yml')\n",
    "        args.pop('conf_exp')\n",
    "\n",
    "        save_dir = 'results/data_assimilation/' + args['exp_id'] + '/'\n",
    "        fn = save_dir + 'out.npy'\n",
    "\n",
    "        out = np.load(res_dir + fn, allow_pickle=True)[()]\n",
    "\n",
    "        J = args['J']\n",
    "        n_steps = args['n_steps']\n",
    "        T_win = args['T_win'] \n",
    "        T_shift = args['T_shift'] if args['T_shift'] >= 0 else T_win\n",
    "        dt = args['dt']\n",
    "\n",
    "        data = out['out']\n",
    "        y, m = out['y'], out['m']\n",
    "        x_sols = out['x_sols']\n",
    "        losses, times = out['losses'], out['times']\n",
    "\n",
    "        assert T_win == out['T_win']\n",
    "\n",
    "        mses = np.zeros(((data.shape[0] - T_win) // T_shift + 1, data.shape[1]))\n",
    "        for i in range(len(mses)):\n",
    "            mse = np.nanmean((x_sols[i:i+1] - data)**2, axis=(-2, -1))\n",
    "            mses[i] = mse[i *T_shift]\n",
    "\n",
    "        if ifplot:\n",
    "\n",
    "            xx = np.arange(0, data.shape[0] - T_win, T_shift)\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.plot(xx, mses, 'o-', color=clrs[eid], linewidth=2.5)\n",
    "            plt.xlim(0, len(data))\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.plot(xx, np.nanmean(mses, axis=1), 'o-', color=clrs[eid], linewidth=2.5)\n",
    "            plt.xlim(0, len(data))\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.plot(xx, mses, 'o-', color=clrs[eid], linewidth=2.5)\n",
    "            plt.axis([0, len(data)-1, 0, 2])\n",
    "            print(np.nanmean(mses[1:]))\n",
    "            lgnd.append('window length='+str(T_win))\n",
    "\n",
    "        rmses_total[eid] = np.sqrt(np.nanmean(mses))\n",
    "        win_lens[eid] = T_win\n",
    "\n",
    "    if ifplot: \n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title('individial trials')\n",
    "        plt.ylabel('initial state MSE')\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.title('averages over trials')\n",
    "        plt.legend(lgnd[:3])\n",
    "        plt.xlabel('time t')\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.title('inidividual trials, zoom-in on small MSEs')\n",
    "        plt.show()\n",
    "        \n",
    "    return win_lens, rmses_total\n",
    "\n",
    "\n",
    "def get_pred_rmses_4DVar_exp(exp_id):\n",
    "\n",
    "    exp_names = os.listdir('experiments_DA/')   \n",
    "    conf_exp = exp_names[np.where(np.array([name[:2] for name in exp_names])==str(exp_id))[0][0]][:-4]\n",
    "    args = setup_4DVar(conf_exp=f'experiments_DA/{conf_exp}.yml')\n",
    "    args.pop('conf_exp')\n",
    "\n",
    "    assert args['T_win'] == 64 # we want 4d integration window here\n",
    "\n",
    "    K,J = args['K'], args['J']\n",
    "    T_win = args['T_win']\n",
    "\n",
    "    model_pars = {\n",
    "        'exp_id' : args['model_exp_id'],\n",
    "        'model_forwarder' : 'rk4_default',\n",
    "        'K_net' : args['K'],\n",
    "        'J_net' : args['J'],\n",
    "        'dt_net' : args['dt']\n",
    "    }\n",
    "\n",
    "    model, model_forwarder, _ = get_model(model_pars, res_dir=res_dir, exp_dir='')\n",
    "\n",
    "    obs_operator = args['obs_operator']\n",
    "    obs_pars = {}\n",
    "    if obs_operator=='ObsOp_subsampleGaussian':\n",
    "        obs_pars['obs_operator'] = ObsOp_subsampleGaussian\n",
    "        obs_pars['obs_operator_args'] = {'r' : args['obs_operator_r'], 'sigma2' : args['obs_operator_sig2']}\n",
    "    elif obs_operator=='ObsOp_identity':\n",
    "        obs_pars['obs_operator'] = ObsOp_identity\n",
    "        obs_pars['obs_operator_args'] = {}\n",
    "    elif obs_operator=='ObsOp_rotsampleGaussian':\n",
    "        obs_pars['obs_operator'] = ObsOp_rotsampleGaussian\n",
    "        obs_pars['obs_operator_args'] = {'frq' : args['obs_operator_frq'], \n",
    "                                         'sigma2' : args['obs_operator_sig2']}\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    model_observer = obs_pars['obs_operator'](**obs_pars['obs_operator_args'])\n",
    "\n",
    "    prior = torch.distributions.normal.Normal(loc=torch.zeros((1,J+1,K)), \n",
    "                                              scale=1.*torch.ones((1,J+1,K)))\n",
    "\n",
    "    # ### define generative model for observed data\n",
    "    gen = GenModel(model_forwarder, model_observer, prior, T=T_win, x_init=None)\n",
    "\n",
    "    forecast_win = int(120/1.5) # 5d forecast\n",
    "    eval_every = int(6/1.5) # every 6h\n",
    "\n",
    "\n",
    "    save_dir = 'results/data_assimilation/' + args['exp_id'] + '/'\n",
    "    fn = save_dir + 'out.npy'\n",
    "\n",
    "    out = np.load(res_dir + fn, allow_pickle=True)[()]\n",
    "\n",
    "    J = args['J']\n",
    "    n_steps = args['n_steps']\n",
    "    T_win = args['T_win'] \n",
    "    T_shift = args['T_shift'] if args['T_shift'] >= 0 else T_win\n",
    "    dt = args['dt']\n",
    "\n",
    "    data = out['out']\n",
    "    y, m = out['y'], out['m']\n",
    "    x_sols = out['x_sols']\n",
    "    losses, times = out['losses'], out['times']\n",
    "\n",
    "    assert T_win == out['T_win']\n",
    "\n",
    "    mses = np.zeros(((data.shape[0] - forecast_win - T_win) // T_shift + 1, forecast_win//eval_every+1, y.shape[1]))\n",
    "    for i in range(len(mses)):\n",
    "        forecasts = gen._forward(x=as_tensor(x_sols[i]), T_obs=T_win + np.arange(0,forecast_win+1,eval_every))\n",
    "        n = i * T_shift + T_win\n",
    "        for j in range(mses.shape[1]): # loop over integration windows\n",
    "            forecast = forecasts[j].detach().cpu().numpy()\n",
    "            y_obs = data[n+j*eval_every] # sortL96intoChannels(y[n+j*eval_every],J=J)\n",
    "            mses[i,j] = np.nanmean((forecast - y_obs)**2, axis=(-2, -1))\n",
    "\n",
    "    pred_lens = 1.5/24 * np.arange(0, forecast_win+1, eval_every)\n",
    "\n",
    "\n",
    "    return pred_lens, np.sqrt(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ids_minimalNet = ['14', '15', '16', '17', '18', '19', '20', '21']\n",
    "exp_ids_bilinNet = ['22', '23', '24', '25', '26', '27', '28', '29']\n",
    "exp_ids_analyticNet = ['30', '31', '32', '33', '34', '35', '36', '37']\n",
    "exp_ids_deepNet = ['38', '39', '40', '41', '42', '43', '44', '45']\n",
    "\n",
    "win_lens_minimalNet, rmses_analysis_minimalNet = get_analysis_rmses_4DVar_exp(exp_ids=exp_ids_minimalNet)\n",
    "win_lens_bilinNet, rmses_analysis_bilinNet = get_analysis_rmses_4DVar_exp(exp_ids=exp_ids_bilinNet)\n",
    "win_lens_analyticNet, rmses_analysis_analyticNet = get_analysis_rmses_4DVar_exp(exp_ids=exp_ids_analyticNet)\n",
    "win_lens_deepNet, rmses_analysis_deepNet = get_analysis_rmses_4DVar_exp(exp_ids=exp_ids_deepNet)\n",
    "\n",
    "pred_lens_minimalNet, rmses_pred__minimalNet = get_pred_rmses_4DVar_exp(exp_id='21')\n",
    "pred_lens_bilinNet, rmses_pred__bilinNet = get_pred_rmses_4DVar_exp(exp_id='29')\n",
    "pred_lens_analyticNet, rmses_pred_analyticNet = get_pred_rmses_4DVar_exp(exp_id='37')\n",
    "pred_lens_deepNet, rmses_pred_deepNet = get_pred_rmses_4DVar_exp(exp_id='45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=14\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.plot(win_lens_analyticNet*1.5/24, rmses_analysis_analyticNet, \n",
    "         '-', color='r', linewidth=2.5, label='analytic')\n",
    "plt.plot(win_lens_minimalNet*1.5/24, rmses_analysis_minimalNet, \n",
    "         '-', color='b', linewidth=2.5, label='sqrtNet')\n",
    "plt.plot(win_lens_bilinNet*1.5/24, rmses_analysis_bilinNet, \n",
    "         '-', color='orange', linewidth=2.5, label='bilinNet')\n",
    "plt.plot(win_lens_deepNet*1.5/24, rmses_analysis_deepNet, \n",
    "         '-', color='g', linewidth=2.5, label='deepNet')\n",
    "plt.xlabel('integration window length [d]', fontsize=fontsize)\n",
    "plt.ylabel('RMSE', fontsize=fontsize)\n",
    "plt.yticks([0.4, 0.5, 0.6, 0.7], fontsize=fontsize)\n",
    "plt.xticks(0.5*np.arange(1, 8.1), fontsize=fontsize)\n",
    "plt.legend(fontsize=fontsize, frameon=False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.plot(pred_lens_analyticNet,np.nanmean(rmses_pred_analyticNet,axis=(0,-1)), \n",
    "         '-', color='r', linewidth=2.5, label='analytic')\n",
    "plt.plot(pred_lens_minimalNet,np.nanmean(rmses_pred__minimalNet,axis=(0,-1)), \n",
    "         '-', color='b', linewidth=2.5, label='sqrtlNet')\n",
    "plt.plot(pred_lens_bilinNet,np.nanmean(rmses_pred__bilinNet,axis=(0,-1)), \n",
    "         '-', color='orange', linewidth=2.5, label='bilinNet')\n",
    "plt.plot(pred_lens_bilinNet,np.nanmean(rmses_pred__bilinNet,axis=(0,-1)), \n",
    "         '-', color='g', linewidth=2.5, label='deepNet')\n",
    "plt.xlabel('forecast time [d]', fontsize=fontsize)\n",
    "plt.ylabel('RMSE', fontsize=fontsize)\n",
    "plt.yticks([0.5, 1.0, 1.5], fontsize=fontsize)\n",
    "plt.xticks(np.arange(5.1), fontsize=fontsize)\n",
    "plt.legend(fontsize=fontsize, frameon=False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.savefig(res_dir + 'figs/4DVar.pdf', bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametrization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L96_emulator.eval import get_rollout_fun, plot_rollout\n",
    "from L96_emulator.parametrization import Parametrized_twoLevel_L96, Parametrization_lin\n",
    "from L96_emulator.networks import Model_forwarder_rk4default\n",
    "from L96_emulator.run_parametrization import setup_parametrization\n",
    "from L96_emulator.data_assimilation import get_model\n",
    "from L96_emulator.util import as_tensor, dtype_np, sortL96intoChannels, sortL96fromChannels\n",
    "from L96sim.L96_base import f1, f2, pf2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "exp_id = '01'\n",
    "\n",
    "exp_names = os.listdir('experiments_parametrization/')   \n",
    "conf_exp = exp_names[np.where(np.array([name[:2] for name in exp_names])==str(exp_id))[0][0]][:-4]\n",
    "args = setup_parametrization(conf_exp=f'experiments_parametrization/{conf_exp}.yml')\n",
    "args.pop('conf_exp')\n",
    "\n",
    "save_dir = 'results/parametrization/' + args['exp_id'] + '/'\n",
    "out = np.load(res_dir + save_dir + 'out.npy', allow_pickle=True)[()]\n",
    "\n",
    "T_dur = 5000\n",
    "X_init = out['X_init']\n",
    "\n",
    "model_pars = {\n",
    "    'exp_id' : args['model_exp_id'],\n",
    "    'model_forwarder' : args['model_forwarder'],\n",
    "    'K_net' : args['K'],\n",
    "    'J_net' : 0,\n",
    "    'dt_net' : args['dt']\n",
    "}\n",
    "# trained parametrized model\n",
    "model, model_forwarder, _ = get_model(model_pars, res_dir=res_dir, exp_dir='')\n",
    "param_train = Parametrization_lin(a=as_tensor(out['param_train_state_dict']['a']), \n",
    "                                  b=as_tensor(out['param_train_state_dict']['b']))\n",
    "model_parametrized_train = Parametrized_twoLevel_L96(emulator=model, parametrization=param_train)\n",
    "model_forwarder_parametrized_train = Model_forwarder_rk4default(model=model_parametrized_train, dt=args['dt'])\n",
    "\n",
    "# initial and reference parametrized models\n",
    "param_ref = Parametrization_lin(a=as_tensor(np.array([-0.31])), b=as_tensor(np.array([-0.2])))\n",
    "param_init = Parametrization_lin(a=as_tensor(np.array([-0.75])), b=as_tensor(np.array([-0.4])))\n",
    "model_parametrized_init = Parametrized_twoLevel_L96(emulator=model, parametrization=param_init)\n",
    "model_forwarder_parametrized_init = Model_forwarder_rk4default(model=model_parametrized_init, dt=args['dt'])\n",
    "model_parametrized_ref = Parametrized_twoLevel_L96(emulator=model, parametrization=param_ref)\n",
    "model_forwarder_parametrized_ref = Model_forwarder_rk4default(model=model_parametrized_ref, dt=args['dt'])\n",
    "\n",
    "# ground-truth high-res model\n",
    "dX_dt = np.empty(args['K']*(args['J']+1), dtype=dtype_np)\n",
    "def fun(t, x):\n",
    "    return f2(x, args['l96_F'], args['l96_h'], args['l96_b'], args['l96_c'], dX_dt, args['K'], args['J'])\n",
    "class Torch_solver(torch.nn.Module):\n",
    "    # numerical solver (from numpy/numba/Julia)\n",
    "    def __init__(self, fun):\n",
    "        self.fun = fun\n",
    "    def forward(self, x):\n",
    "        x = sortL96fromChannels(x.detach().cpu().numpy()).flatten()\n",
    "        return sortL96intoChannels(np.atleast_2d(self.fun(0., x)), J=args['J'])\n",
    "model_forwarder_np = Model_forwarder_rk4default(Torch_solver(fun), dt=args['dt'])\n",
    "\n",
    "model_forwarders = [Model_forwarder_rk4default(model, dt=args['dt']),\n",
    "                    model_forwarder_parametrized_init, \n",
    "                    model_forwarder_parametrized_train,\n",
    "                    model_forwarder_parametrized_ref,\n",
    "                    model_forwarder_np]\n",
    "X_inits = [X_init[:,:args['K']].copy(), \n",
    "           X_init[:,:args['K']].copy(), \n",
    "           X_init[:,:args['K']].copy(), \n",
    "           X_init[:,:args['K']].copy(), \n",
    "           X_init.copy()]\n",
    "Js = [0, 0, 0, 0, args['J']]\n",
    "panel_titles=['one-level L96', \n",
    "              'initial param.', \n",
    "              'learned param.', \n",
    "              'reference param.', \n",
    "              'two-level L96']\n",
    "sols = [np.nan for n in range(len(model_forwarders))]\n",
    "for i_model in range(len(model_forwarders)): \n",
    "    \n",
    "    model_forwarder_i, X_init_i, J_i = model_forwarders[i_model], X_inits[i_model], Js[i_model]\n",
    "\n",
    "    def model_simulate(y0, dy0, n_steps):\n",
    "        x = np.empty((n_steps+1, *y0.shape[1:]))\n",
    "        x[0] = y0.copy()\n",
    "        xx = as_tensor(x[0]).reshape(1,1,-1)\n",
    "        for i in range(1,n_steps+1):\n",
    "            xx = model_forwarder_i(xx.reshape(1,J_i+1,-1))\n",
    "            x[i] = xx.detach().cpu().numpy().copy()\n",
    "        return x\n",
    "\n",
    "    print('forwarding model ' + panel_titles[i_model])\n",
    "    sols[i_model] = model_simulate(y0=sortL96intoChannels(X_init_i,J=J_i), dy0=None, n_steps=T_dur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=14\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "rmses = np.zeros((len(model_forwarders), T_dur+1))\n",
    "for i_model in range(len(model_forwarders)): \n",
    "    \n",
    "    plt.subplot(2,len(model_forwarders),i_model+1)\n",
    "    plt.imshow(sortL96fromChannels(sols[i_model][:,:1,:]).T, aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title(panel_titles[i_model], fontsize=fontsize)\n",
    "    \n",
    "    if i_model == 0:\n",
    "        plt.ylabel('location k', fontsize=fontsize)\n",
    "    if i_model == 2:\n",
    "        plt.xlabel('time [steps]', fontsize=fontsize)\n",
    "        \n",
    "    rmses[i_model,:] = np.sqrt(np.mean((sols[i_model][:,0,:] - sols[-1][:,0,:])**2, axis=1))\n",
    "    plt.yticks([], fontsize=fontsize)\n",
    "    plt.xticks([0, T_dur/2, T_dur], fontsize=fontsize)\n",
    "    \n",
    "plt.subplot(2,2,3)\n",
    "plt.text(0.5, 0.5, 'tbd')\n",
    "plt.ylabel('parametrization parameters', fontsize=fontsize)\n",
    "plt.xlabel('dataset size', fontsize=fontsize)\n",
    "plt.xticks([], fontsize=fontsize)\n",
    "plt.yticks([], fontsize=fontsize)\n",
    "\n",
    "    \n",
    "plt.subplot(2,2,4)\n",
    "for i_model in range(len(model_forwarders)-1):\n",
    "    plt.plot(rmses[i_model], label=panel_titles[i_model])\n",
    "plt.legend(fontsize=fontsize, frameon=False)\n",
    "plt.ylabel('RMSE', fontsize=fontsize)\n",
    "plt.xlabel('time [steps]', fontsize=fontsize)\n",
    "plt.xticks([0, T_dur/2, T_dur], fontsize=fontsize)\n",
    "plt.yticks([0, 3, 6], fontsize=fontsize)\n",
    "plt.savefig(res_dir + 'figs/param.pdf', bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
